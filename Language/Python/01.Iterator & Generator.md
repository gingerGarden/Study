# Iterator와 Generator
위 둘은 데이터를 순차적으로 처리하고, 특히 대용량 데이터를 효율적으로 다룰 때 매우 중요한 개념임

<br>

## A. 기본 개념
### A-1. Iterable 객체
* 정의: `for` 루프 등으로 그 안의 요소들을 하나씩 꺼낼 수 있는 모든 객체.
* 예시: 리스트(list), 튜플(tuple), 딕셔너리(dict), 세트(set), 문자열(str) 등
* 특징:
> * 내부에 `__iter__()` 메소드를 가지고 있음. 이 메소드를 호출하면 **이터레이터**를 반환함.
> * Iterable은 `__iter__()` 외에도 종종 `__getitem__()`을 구현한 객체도 포함 (list는 슬라이싱 때문에 __getitem__()도 구현)
>> * 이는 Iterable 이지만 Iterator는 아님
* 참고: 이터러블 자체는 몇 번이고 반복해서 사용할 수 있음 (일회용이 아님).
* 예시
```
my_list = [1, 2, 3]
gen = (x for x in my_list)
print(next(gen))  # 1
# gen을 다시 순회하려면 새로 생성 필요
gen = (x for x in my_list)
```
<br>
<br>

### A-2. Iterator
* 정의: `__iter__()`와 `__next__()`를 구현한 객체로, 내부 상태(진행 위치)를 관리
> * 값을 차례대로 꺼낼 수 있는 상태를 가진 객체. 어디까지 값을 꺼냈는지 기억하고 있다가, 다음 값을 요청하면 그 다음 값을 반환
* 주요 메소드:
> * `__iter__()`: 자기 자신(self) 반환
>> * Iterator가 이미 상태(state)를 관리하고 있으므로, 새로운 Iterator 객체를 만들 필요가 없음
>> * 때문에 for 루프와 함께 동작 가능
> * `__next__()`: 다음 값 반환, 없으면 `StopIteration`
* 생성: `iter(iterable)` 내장 함수 사용
> * 더 이상 반환할 값이 없으면 StopIteration 예외 발생`
```
my_list = [1, 2, 3]

# my_list (이터러블) 로부터 my_iterator (이터레이터)를 생성
my_iterator = iter(my_list)

print(type(my_list))      # <class 'list'>
print(type(my_iterator))  # <class 'list_iterator'>

# next() 함수로 값을 하나씩 꺼냄
print(next(my_iterator))  # 1
print(next(my_iterator))  # 2
print(next(my_iterator))  # 3

# 더 이상 꺼낼 값이 없으면 StopIteration 예외 발생
# print(next(my_iterator)) # StopIteration
```
<br>

* `for` 루프는 내부적으로 이 과정을 자동으로 처리해줌
> * `iter()`를 호출하여 이터레이터를 얻음
> * `StopIteration` 예외가 발생할 때까지 next()를 계속 호출하여 값을 가져옴
* 이터레이터의 생성
> * 클래스에 `__iter__`와 `__next__` 메소드를 구현하여 직접 이터레이트를 만들 수 있음
```
class Counter:
    def __init__(self, stop):
       self.current = 0
       self.stop = stop

    def __iter__(self):
       # 이터레이터는 __iter__에서 자기 자신(self)을 반환해야 합니다.
       return self

    def __next__(self):
        if self.current < self.stop:
            r = self.current
            self.current += 1
            return r
        else:
            # 루프를 멈추기 위해 StopIteration 예외를 발생시킵니다.
            raise StopIteration
        
# Counter 객체를 for 루프에서 사용
for i in Counter(5):
    print(i) # 0, 1, 2, 3, 4 출력
```
<br>
<br>

### A-3. Generator
* 정의: 이터레이터를 생성해주는 함수. 일반 함수와 비슷하지만, `return` 대신 `yield` 키워드를 사용하여 값 반환
* 특징:
> * `yield`를 만나면 함수는 그 상태를 기억한 채로 잠시 멈추고, `yield` 된 값을 호출자에게 반환
> * 다시 호출되면 (예: `next()` 호출) 멈췄던 지점부터 실행 재개
> * 모든 실행이 끝나면 자동으로 `StopIteration` 예외 발생
> * 로컬 변수뿐 아니라, **스택 프레임 상태(try-except, 루프 포인터, 호출 스택)**까지 모두 보존.
>> * 이로인해 호출자와의 양방향 통신(`send()`, `throw()`) 가능
* 장점: 이터레이터 클래스를 만드는 것보다 훨씬 간결하고 편리하며, 메모리를 효율적으로 사용
* 제네레이터 함수의 생성
```
def counter_generator(stop):
    current = 0
    while current < stop:
        yield current  # 값을 반환하고 여기서 실행을 멈춤
        current += 1   # 다음 루프에서 여기서부터 실행

# 제너레이터 함수를 호출하면 제너레이터 객체(이터레이터의 일종)가 반환됨
my_gen = counter_generator(5)
print(type(my_gen)) # <class 'generator'>

 # next()로 값을 하나씩 꺼낼 수 있음
print(next(my_gen)) # 0
print(next(my_gen)) # 1

 # for 루프에서도 당연히 사용 가능
for i in my_gen:
     print(i) # 2, 3, 4 출력 (앞에서 0, 1을 꺼냈으므로)
```
<br>

* 리스트 컴프리헨션([])과 비슷하지만, 괄호(())를 사용하여 제너레이터를 한 줄로 만들 수 있음
```
# 리스트 컴프리헨션: 모든 값을 메모리에 올리는 리스트를 생성
list_comp = [i * i for i in range(10)]

# 제너레이터 표현식: 필요할 때 값을 하나씩 생성하는 제너레이터 객체를 생성
gen_expr = (i * i for i in range(10))

print(list_comp)  # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
print(gen_expr)   # <generator object <genexpr> at 0x...>

# 제너레이터는 메모리를 훨씬 효율적으로 사용합니다.
# 예를 들어 range(10000000) 이라면, 리스트는 엄청난 메모리를 사용하지만
# 제너레이터는 거의 메모리를 차지하지 않습니다.
```

<br>
<br>

### A-4. Iterator와 Generator의 핵심 차이점
|구분|Iterator|Generator|
|----|----|----|
|**구현 방식**|클래스(`__iter__`, `__next__` 구현)|함수(`yield` 키워드 사용) 또는 표현식|
|**상태 저장**|인스턴스 변수(e.g., `self.current`)|`yield` 지점에서 코드 실행 상태가 자동으로 저장됨|
|**생성 시점 메모리 사용**|데이터를 미리 생성 안 함|데이터를 미리 생성 안 함|
|**코드 길이**|상대적으로 길고 복잡함|매우 간결하고 직관적임|
|**리소스 해제**|명시적 관리 필요(`del`, `close`)|`StopIteration` 이후 자동 해제, `with`로 관리 가능|
|**Thread-Safety**|상태 관리 코드에 따라 달라짐|기본적으로 비동기 사용 불가(Python 3.6+ 비동기 제너레이터 등장)|
|**사용 사례**|복잡한 상태 관리나 메소드가 필요한 경우|대부분의 순차 데이터 처리|

* 대부분의 경우 제너레이터를 사용
> * 코드가 훨씬 간결하고 Pythonic하며, 이터레이터가 하는 모든 일을 할 수 있음
> * 특히 대용량 파일 처리, 데이터 스트리밍 등 메모리 효율성이 중요할 때 필수

* 사용자 정의 이터레이터 클래스는 다음 경우에 사용 고려
> * 이터레이터 객체가 `__next__` 외에 다른 메소드(e.g., `rewind()` - 되감기)를 가져야 할 때
> * 상태를 관리하는 로직이 매우 복잡하여 클래스도 캡슐화하는 것이 더 명확할 때

<br>
<br>

### A-5. 이터레이터/제너레이터는 일회용 (Exhaustible)
* Iterator와 Generator은 일회용임
* `for` 루프나 `list()` 변환 등으로 모든 값을 소진하고 나면, 객체는 **비어있는** 상태가 되어 다시 값을 꺼낼 수 없음
* 다시 순회하고자 한다면 원본 이터러블 객체로부터 새로운 이터레이터/제너레이터를 생성해야함
```
# 제너레이터 예시
my_gen = (i for i in range(3))
print(list(my_gen))  # [0, 1, 2]
print(list(my_gen))  # []  <-- 이미 모든 값을 소진하여 비어 있음

# 이터레이터 예시
my_list = [10, 20, 30]
my_iterator = iter(my_list)
print(list(my_iterator)) # [10, 20, 30]
print(list(my_iterator)) # [] <-- 이터레이터도 소진됨

# 다시 순회하려면 새로운 이터레이터를 만들어야 함
new_iterator = iter(my_list)
print(next(new_iterator)) # 10
```

<br>
<br>

### A-6. `return`과 `yield`
* `return`
> * 함수를 즉시 종료하고 값을 반환
> * 함수가 한 번에 한 개의 값만 반환할 수 있으며, 종료 이후 재실행되지 않음
* `yield`
> * 함수를 **종료시키지 않고** "값을 내보낸 뒤(emit) 잠시 멈춤(pausing)"
> * 그 상태(로컬 변수, 제어 흐름 위치 등)를 기억하고 있다가, 다음 호출 시점에 그 상태로부터 다시 실행을 이어감
> * 여러 번 `yield`를 통해 순차적으로 여러 값을 차례차례 내보낼 수 있음

<br>
<br>
<br>

## B. 고급 제너레이터 기능
### B-1. 제너레이터 메소드: `send()`, `throw()`, `close()`
```
# 단순 카운터 제너레이터 예시
def echo():
    received = None
    while True:
        # 외부에서 보낸 값을 받아서 다시 돌려줌
        received = yield received

gen = echo()
print(next(gen))        # 첫 번째 next(): 첫 yield까지 실행, yield된 값은 None
print(gen.send('A'))    # 'A'가 received에 할당되어 yield된 값도 'A'
print(gen.send('B'))    # 'B'가 received에 할당되어 yield된 값도 'B'

# 에러를 내부로 전달하고 싶을 때
try:
    gen.throw(ValueError, "에러 발생")
except ValueError as e:
    print("Generator 내부에서 처리되지 않음:", e)

# 제너레이터 강제 종료
gen.close()
```
* `send(value)`: 제너레이터에 값을 보내고, 다음 yield 위치에서 다시 실행
> * `send()`는 `next()`의 확장이라 볼 수 있음
> * 'send()'를 사용하기 위해선 Generator가 반드시 `yield` 문에서 멈춰 있어야 함.
> * 따라서 Generator를 막 생성했다면, 가장 먼저 `next(gen)` 또는 `gen.send(None)`을 호출하여 첫 번째 `yield`까지 실행시켜야 함. 이후부터 `send()`로 값을 주고 받을 수 있음.
> * 예제의 `print(next(gen))`이 위 역할 수행
> * `send(value)`는 `next()`와 동일하게 다음 yield 지점까지 실행하되, yield 표현식의 결과로 value 전달. 즉 `value=(yield ...)` 형태로 제너레이터 내부에서 값을 받을 수 있음.
* `throw(exc_type, exc_val)`: 제너레이터 내부에서 예외를 발생시켜 예외 처리 루틴을 시험
* `close()`: GeneratorExit 예외를 발생시켜 제너레이터를 종료

<br>

### B-2. `yield from`을 이용한 하위 제너레이터 위임
```
# 중첩 제너레이터를 간단히 연결
def sub_generator():
    for i in range(3):
        yield i

def main_generator():
    # sub_generator에서 yield되는 값을 모두 위임
    yield from sub_generator()
    yield '끝'

for x in main_generator():
    print(x)  # 0,1,2,'끝'
```
* 복잡한 반복 로직을 분할하고 재사용할 때 유용
* 스택 프레임을 깔끔하게 유지하면서 하위 제너레이터와 양방향 통신 가능

<br>
<br>
<br>

## C. 제너레이터 표현식 vs 리스트 컴프리헨션
|구분|리스트 컴프리헨션|제너레이터 표현식|
|---|---|---|
|구문|`[f(x) for x in it]`|`(f(x) for x in it)`|
|메모리|전체 결과 리스트 저장|필요 시 하나씩 생성|
|표준 함수|`map(), filter(), zip(), enumerate() 등|이터레이터 반환|
|`len()`지원 여부|길이(len), 인덱싱 지원|길이 미지원(len 불가), 인덱싱 불가|
|사용 예|짧은 리스트 생성|무제한 스트림, 대용량 데이터 처리|

```
# 파일 라인 단위 처리 예시
# 리스트로 읽으면 메모리 부담
lines_list = open('bigfile.txt').read().splitlines()
# 제너레이터로 처리하면 한 줄씩 스트리밍
lines_gen = (line.strip() for line in open('bigfile.txt'))
for line in lines_gen:
    process(line)
```

<br>
<br>
<br>

## D. Practical Use Cases
1. **대용량 파일 처리**: 한 번에 메모리에 올리지 않고, 한 줄씩 혹은 청크 단위로 처리
```
def read_lines(path):
    with open(path) as f:
        for line in f:
            yield line.strip()
```
2. **네트워크 스트리밍**: 소켓 데이터나 HTTP 응답 바이트 스트림을 `yield`로 핸들링
```
def stream_reader(sock):
    try:
        while True:
            chunk = sock.recv(1024)
            if not chunk:
                break
            yield chunk
    finally:
        sock.close()
```
3. **파이프라인 구축**: 서로 다른 처리 단계를 제너레이터 체이닝하여 간결한 데이터 흐름 구성
```
# 파이프라인 예시: 필터 → 변환 → 집계
def read_numbers():
    for i in range(100_000_000):
        yield i

def even_filter(nums):
    for n in nums:
        if n % 2 == 0:
            yield n

def square(nums):
    for n in nums:
        yield n * n

pipeline = square(even_filter(read_numbers()))
print(next(pipeline))  # 0
print(next(pipeline))  # 4
```

* 파이프라인에서 **지연 평가(Lazy Evalation)**
> * 위 파이프라인의 가장 큰 특징은 지연 평가(Lazy Evaluation)임.
> * `next(pipeline)` 호출 전까지 `read_numbers`의 숫자 생성, `even_filter`의 필터링, `square`의 제곱 계산이 전혀 일어나지 않음
> * 딱 필요한 만큼만 데이터가 흘러가며 처리되므로, `read_numbers`가 무한한 스트림이라도 시스템에 부담을 주지 않고 처리할 수 있음

<br>
<br>
<br>

## E. itertools와 제너레이터 유틸리티
* `itertools.islice()`, `chain()`, `tee()`, `groupby()` 등으로 제너레이터 조작
```
from itertools import cycle, repeat, count

# 무한 반복
for i in cycle("AB"):    # A B A B A ...
    print(i)
    break  # 주의: 무한루프

# 특정 값 반복
for i in repeat(10, 3):  # 10, 10, 10
    print(i)

# 무한 카운터
for i in count(5, 2):    # 5, 7, 9, ...
    print(i)
    if i > 10:
        break
```

<br>
<br>
<br>

## F. 비동기 제너레이터 (Python 3.6+)
* `async def`와 `async for`를 사용하여 비동기 스트림 처리
* Python 3.8+: async for + async with 조합 가능
* 비동기 스트림 처리 시 HTTP 클라이언트 라이브러리 (aiohttp)와 궁합 좋음
```
import asyncio
async def async_counter(n):
    for i in range(n):
        await asyncio.sleep(0.1)
        yield i

async def main():
    async for num in async_counter(3):
        print(num)

asyncio.run(main())  # 0,1,2 출력
```

<br>
<br>
<br>

## G. 권장 실전 팁
* 단순 순차 데이터 처리에는 제너레이터로 충분
* 복잡한 상태 관리나 메소드가 필요할 땐 사용자 정의 이터레이터 고려
* 제너레이터는 Lazy Evaluation 덕분에 Pandas 등 대용량 처리 라이브러리와 조합시 OOM(Out of Memory) 위험 감소.
* yield from으로 코드 재사용성과 가독성 향상
* itertools 활용해 성능 최적화
* 비동기 I/O에는 async generator 적극 활용
* 예외/리소스 관리:
> *컨텍스트 매니저 래핑 패턴 사용
```
from contextlib import contextmanager
@contextmanager
def gen_cm(func, *args, **kwargs):
    gen = func(*args, **kwargs)
    try:
        yield gen
    finally:
        gen.close()
```
* 요약: 제너레이터는 Pythonic하고 메모리 효율적인 반복 스트림 처리 기법이며, `yield`와 `yield from`, `async comprehension` 등으로 복잡한 파이프라인까지 구현 가능합니다.
